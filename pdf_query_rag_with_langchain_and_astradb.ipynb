{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1Zh5yGzx426",
        "outputId": "d9f9a81f-f65f-480a-c473-a3bd7d63ed29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/232.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain_community openai python-dotenv cassio datasets tiktoken PyPDF2\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Cassandra\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "import cassio"
      ],
      "metadata": {
        "id": "OvMc57D9yEN0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader"
      ],
      "metadata": {
        "id": "yONWDlBnycV0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "ASTRADB_APPLICATION_TOKEN=userdata.get('ASTRADB_APPLICATION_TOKEN')\n",
        "ASTRADB_ID=userdata.get('ASTRADB_ID')\n",
        "\n",
        "OPENAI_API_KEY=userdata.get('OPEN_AI_KEY')"
      ],
      "metadata": {
        "id": "xE4yHCmUy2PX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdfreader = PdfReader('./attention.pdf')"
      ],
      "metadata": {
        "id": "dun-Wtj20B0y"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text = ''\n",
        "for i,page in enumerate(pdfreader.pages):\n",
        "  content = page.extract_text()\n",
        "  if content:\n",
        "    raw_text += content\n",
        "\n",
        "raw_text"
      ],
      "metadata": {
        "id": "CdYdLL861h7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cassio.init(token=ASTRADB_APPLICATION_TOKEN, database_id=ASTRADB_ID)"
      ],
      "metadata": {
        "id": "xS29Bhsd12kf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=OpenAI(openai_api_key=OPENAI_API_KEY,)\n",
        "embeddings=OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY, model='text-embedding-3-small')"
      ],
      "metadata": {
        "id": "PRy5D7Pw2b8Z"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "astra_vector_store = Cassandra(\n",
        "    embedding=embeddings,\n",
        "    table_name=\"qa_mini_demo\",\n",
        "    session=None,\n",
        "    keyspace=None\n",
        ")\n"
      ],
      "metadata": {
        "id": "H8Ee9ITj2rA8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "texts = CharacterTextSplitter(\n",
        "    separator='\\n',\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=100,\n",
        "    length_function=len\n",
        ").split_text(raw_text)"
      ],
      "metadata": {
        "id": "rshKZtr73wvD"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts), texts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ThKUfbP4fb7",
        "outputId": "95c1cdda-ab03-45d4-cbc6-1d35f3572722"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102,\n",
              " 'Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.comNoam Shazeer∗\\nGoogle Brain\\nnoam@google.comNiki Parmar∗\\nGoogle Research\\nnikip@google.comJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.comAidan N. Gomez∗ †\\nUniversity of Toronto')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "astra_vector_store.add_texts(texts[:25])\n",
        "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
      ],
      "metadata": {
        "id": "O4UI250z4gTM"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "\n",
        "  query_text = input(\"Enter your question or type quit to exit: \")\n",
        "\n",
        "  if query_text == 'quit':\n",
        "    break\n",
        "  elif query_text == '':\n",
        "    continue\n",
        "\n",
        "  print(\"\\n\\nQuestion: \", query_text)\n",
        "  answer = astra_vector_index.query(query_text, llm=llm).strip()\n",
        "  print(\"\\nAnswer: \", answer)\n",
        "\n",
        "  print(\"\\nFirst document by relavance: \")\n",
        "\n",
        "  for doc , score in astra_vector_store.similarity_search_with_score(query_text, k=4):\n",
        "    print(\"[%0.4f] \\\"%s ... \\\"\" %(score, doc.page_content[:84]))\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SyL_5uk5fqV",
        "outputId": "d80afba2-b381-4d7e-c9c6-3f77e2e821f9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your question or type quit to exit: What is attention ?\n",
            "\n",
            "\n",
            "Question:  What is attention ?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Answer:  Attention is a mechanism used in sequence modeling and transduction models that allows for modeling of dependencies without regard to their distance in the input or output sequences. It involves using queries and keys to compute the weights on values, and can be used in tasks such as reading comprehension, summarization, and textual entailment.\n",
            "\n",
            "First document by relavance: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.7574] \"described in section 3.2.\n",
            "Self-attention, sometimes called intra-attention is an att ... \"\n",
            "[0.7096] \"3Scaled Dot-Product Attention\n",
            " Multi-Head Attention\n",
            "Figure 2: (left) Scaled Dot-Prod ... \"\n",
            "[0.7031] \"Attention mechanisms have become an integral part of compelling sequence modeling an ... \"\n",
            "[0.6993] \"We call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The inpu ... \"\n",
            "Enter your question or type quit to exit: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-9zQTgaF6jiP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}